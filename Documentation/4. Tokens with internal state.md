# Example: Tokens with internal state

## Literal Matching

In examples so far, token types have looked at individual scalars without context to other scalars that have already been matched.

Without keeping some internal state of what's been matched so far, it's not possible to create a token that matches *cat* but not *cta* since they both start with the same scalar, and have the same set of characters.

A `LiteralToken` is a more complex `TokenType` that uses a target `String` as the basis for tokenization:

````Swift

// implementing as class rather than struct since `canTake(_:)` will have mutating effect.
class LiteralToken: TokenType {

    private let target: String
    private var position: String.UnicodeScalarIndex

    // required by the TokenType protocol, but non-sensical to use
    required convenience init() {
        self.init(target: "")
    }

    // instead, we should initalize instance with the target String we're looking for
    init(target: String) {
        self.target = target
        self.position = target.unicodeScalars.startIndex
    }

    // instead of looking at a set of scalars, the order that the scalar occurs
    // is relevent for the token
    func canTake(_ scalar: UnicodeScalar) -> Bool {

        guard position < target.unicodeScalars.endIndex else {
            return false
        }

        // if the scalar matches the target scalar in the current position, then advance
        // the position and return true
        if scalar == target.unicodeScalars[position] {
            position = target.unicodeScalars.index(after: position)
            return true
        }
        else {
            return false
        }
    }

    // this token is only complete when we've called `canTake(_:)` with the correct sequence
    // of scalars such that `position` has advanced to the endIndex of the target
    var isComplete: Bool {
        return position == target.unicodeScalars.endIndex
    }

    // if we've matched the token completely, it should be invalid if the next scalar
    // matches a letter, this means that literal match of "cat" will not match "catastrophe"
    func completeTokenIsInvalid(whenNextScalarIs scalar: UnicodeScalar?) -> Bool {
        if let next = scalar {
            return !CharacterSet.letters.contains(next)
        }
        else {
            return false
        }
    }

    // token instances are re-used, in most cases this doesn't matter, but because we keep
    // an internal state, we need to reset this instance to start matching again
    func prepareForReuse() {
        position = target.unicodeScalars.startIndex
    }
}

extension String {
    // a convenience to allow us to use `"cat".literalToken` instead of `LiteralToken("cat")`
    var literalToken: LiteralToken {
        return LiteralToken(target: self)
    }
}
````

This allows us to match tokens by specific words. Note in this example that the text 'catastrophe' is not matched.

````Swift
let input = "the cat and the catastrophe duck"
let tokens = input.tokens(from: "cat".literalToken, "duck".literalToken)
tokens.count // -> 2

for token in tokens {
    print("-", "'\(token.text)'")
}
// prints ->
// - cat
// - duck

````

## Template Matching

Another useful pattern would be allow us to look for a matching sequence of scalars but using a template rather than a literal match.

A `DateMatch` is a more complex `TokenType` that uses an internal template as the basis for tokenization:

````Swift

// convenience operator to make matching CharacterSet to scalar in a switch statement
infix operator ~=
func ~= (option: CharacterSet, input: UnicodeScalar) -> Bool {
    return option.contains(input)
}

class DateMatch: TokenType {

    let template = "00/00/00"
    var position: String.UnicodeScalarIndex

    required init() {
        position = template.unicodeScalars.startIndex
    }

    func canTake(_ scalar: UnicodeScalar) -> Bool {

        guard position < template.unicodeScalars.endIndex else {
            // we've matched all of the template
            return false
        }

        switch (template.unicodeScalars[position], scalar) {
        case ("\u{0030}", CharacterSet.decimalDigits), // match with a decimal digit
             ("\u{002F}", "\u{002F}"):                 // match with the '/' character

            position = template.unicodeScalars.index(after: position)
            return true

        default:
            return false
        }
    }

    var isComplete: Bool {
        return position == template.unicodeScalars.endIndex
    }

    func prepareForReuse() {
        position = template.unicodeScalars.startIndex
    }
}
````

This will match tokens for any text that has the format of three pairs of numbers joined with the '/' character:

````Swift
import Mustard

let messyInput = "Serial: #YF 1942-b 12/01/27 (Scanned)"

let tokens = messyInput.tokens(from: DateMatch.tokenizer)
// tokens.count -> 1
// tokens[0].text -> "12/01/27"
````

See [FuzzyMatchTokenTests.swift](/Mustard/MustardTests/FuzzyMatchTokenTests.swift) for a unit test that includes fuzzy matching of a literal String, but ignoring certain characters.
