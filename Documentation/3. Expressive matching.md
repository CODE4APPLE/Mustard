# Example: expressive matching

tokens(from:) -> [Token]

The results returned by `tokens(from:)`returns an array of `Token` where `Token` is a typealias of the tuple  `(tokenizer: TokenType, text: String, range: Range<String.Index>)`

Which requires either type casting (using `as?`) type checking  or type checking (using `is`) for the `tokenizer` element to be useful:

````Swift
import Mustard

let messy = "123Hello world&^45.67"
let tokens = messy.tokens(from: .decimalDigits, .letters)

// using type checking
if tokens[0].tokenizer is EmojiToken {
    print("found emoji token")
}

// using type casting
if let _ = tokens[0].tokenizer as? NumberToken {
    print("found number token")
}

````

This can lead to bugs in your logic-- in the example above neither of the print statements will be executed since the tokenizer used was actually the character sets `.decimalDigits`, and `.letters`.

Mustard can return a strongly typed set of matches if a single `TokenType` is used.

````Swift
import Mustard

let messy = "123Hello world&^45.67"

// call `tokens()` method on string to get matching tokens from string
let numberTokens: [NumberToken.Match] = messy.tokens()

````

Used in this way, this isn't very useful, but it does allow for multiple `TokenType` to be bundled together as a single `TokenType` by implementing a TokenType using an `enum`.

An enum token type can either manage it's own internal state, or potentially act as a lightweight wrapper to existing tokenizers.
Here's an example `TokenType` that acts as a wrapper for word, number, and emoji tokenizers:

````Swift

enum MixedToken: TokenType {

    case word
    case number
    case emoji
    case none // 'none' case not strictly needed, and
              // in this implementation will never be matched

    init() {
        self = .none
    }

    static let wordToken = WordToken()
    static let numberToken = NumberToken()
    static let emojiToken = EmojiToken()

    func canAppend(next scalar: UnicodeScalar) -> Bool {
        switch self {
        case .word: return MixedToken.wordToken.canAppend(next: scalar)
        case .number: return MixedToken.numberToken.canAppend(next: scalar)
        case .emoji: return MixedToken.emojiToken.canAppend(next: scalar)
        case .none:
            return false
        }
    }

    func token(startingWith scalar: UnicodeScalar) -> TokenType? {

        if let _ = MixedToken.wordToken.token(startingWith: scalar) {
            return MixedToken.word
        }
        else if let _ = MixedToken.numberToken.token(startingWith: scalar) {
            return MixedToken.number
        }
        else if let _ = MixedToken.emojiToken.token(startingWith: scalar) {
            return MixedToken.emoji
        }
        else {
            return nil
        }
    }
}
````

Mustard defines a default typealias for `Token` that exposes the specific type in the
results tuple.

````Swift
public extension TokenType {
    typealias Token = (tokenizer: Self, text: String, range: Range<String.Index>)
}
````

Setting your results array to this type gives you the option to use the shorter `tokens()` method,
where Mustard uses the inferred type to perform tokenization.

Since the matches array is strongly typed, you can be more expressive with the results, and the
complier can give you more hints to prevent you from making mistakes.

````Swift

// use the `tokens()` method to grab tokens
let matches: [MixedToken.Match] = "123👩‍👩‍👦‍👦Hello world👶 again👶🏿 45.67".tokens()
// matches.count -> 8

matches.forEach({ match in
    switch (match.tokenizer, match.text) {
    case (.word, let word): print("word:", word)
    case (.number, let number): print("number:", number)
    case (.emoji, let emoji): print("emoji:", emoji)
    case (.none, _): break
    }
})
// prints:
// number: 123
// emoji: 👩‍👩‍👦‍👦
// word: Hello
// word: world
// emoji: 👶
// word: again
// emoji: 👶🏿
// number: 45.67
````
